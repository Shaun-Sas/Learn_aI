{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HousingData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "# Instantiate training and test data\n",
    "train_data = HousingData(X_train, y_train)\n",
    "test_data = HousingData(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.layer_2 = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.2919185351031695\n",
      "Epoch: 2 | Loss: 0.9568203241210576\n",
      "Epoch: 3 | Loss: 0.8231542713612857\n",
      "Epoch: 4 | Loss: 0.7459471826983053\n",
      "Epoch: 5 | Loss: 0.6954145967382793\n",
      "Epoch: 6 | Loss: 0.6591054353891879\n",
      "Epoch: 7 | Loss: 0.6313209860675358\n",
      "Epoch: 8 | Loss: 0.6095845866948366\n",
      "Epoch: 9 | Loss: 0.5920760794883654\n",
      "Epoch: 10 | Loss: 0.5774194837944914\n",
      "Epoch: 11 | Loss: 0.5648809494247228\n",
      "Epoch: 12 | Loss: 0.5540601778101628\n",
      "Epoch: 13 | Loss: 0.5445662426873908\n",
      "Epoch: 14 | Loss: 0.5360970367055596\n",
      "Epoch: 15 | Loss: 0.5284805321685719\n",
      "Epoch: 16 | Loss: 0.5216003885608196\n",
      "Epoch: 17 | Loss: 0.5153286302546307\n",
      "Epoch: 18 | Loss: 0.5097640468470245\n",
      "Epoch: 19 | Loss: 0.5044775192942341\n",
      "Epoch: 20 | Loss: 0.4995887927017933\n",
      "Epoch: 21 | Loss: 0.49505831248406423\n",
      "Epoch: 22 | Loss: 0.4907892578169231\n",
      "Epoch: 23 | Loss: 0.48680452877397606\n",
      "Epoch: 24 | Loss: 0.48305671532621525\n",
      "Epoch: 25 | Loss: 0.4795155458233153\n",
      "Epoch: 26 | Loss: 0.47625702564683997\n",
      "Epoch: 27 | Loss: 0.4732666909972758\n",
      "Epoch: 28 | Loss: 0.47049703493565814\n",
      "Epoch: 29 | Loss: 0.4684126048969477\n",
      "Epoch: 30 | Loss: 0.46580130362965033\n",
      "Epoch: 31 | Loss: 0.4633267465983519\n",
      "Epoch: 32 | Loss: 0.4608893946856405\n",
      "Epoch: 33 | Loss: 0.4587597830550531\n",
      "Epoch: 34 | Loss: 0.45661598514651686\n",
      "Epoch: 35 | Loss: 0.45452665654428775\n",
      "Epoch: 36 | Loss: 0.45256649882153227\n",
      "Epoch: 37 | Loss: 0.45060356709502813\n",
      "Epoch: 38 | Loss: 0.44868095321121\n",
      "Epoch: 39 | Loss: 0.44698607830226694\n",
      "Epoch: 40 | Loss: 0.44530974949110846\n",
      "Epoch: 41 | Loss: 0.4435740791459822\n",
      "Epoch: 42 | Loss: 0.44190070142948173\n",
      "Epoch: 43 | Loss: 0.44029922755705425\n",
      "Epoch: 44 | Loss: 0.4388090079102909\n",
      "Epoch: 45 | Loss: 0.43741913171136926\n",
      "Epoch: 46 | Loss: 0.43605616777246353\n",
      "Epoch: 47 | Loss: 0.43462086627458\n",
      "Epoch: 48 | Loss: 0.43333504853158883\n",
      "Epoch: 49 | Loss: 0.43198768272724847\n",
      "Epoch: 50 | Loss: 0.43082885393454123\n",
      "Epoch: 51 | Loss: 0.4297095639131446\n",
      "Epoch: 52 | Loss: 0.4284718437070337\n",
      "Epoch: 53 | Loss: 0.4272850212475283\n",
      "Epoch: 54 | Loss: 0.42684881114904955\n",
      "Epoch: 55 | Loss: 0.4258218601608545\n",
      "Epoch: 56 | Loss: 0.4246971826796169\n",
      "Epoch: 57 | Loss: 0.42358198631836025\n",
      "Epoch: 58 | Loss: 0.4225168010995162\n",
      "Epoch: 59 | Loss: 0.42145924445575994\n",
      "Epoch: 60 | Loss: 0.4204143118960374\n",
      "Epoch: 61 | Loss: 0.4193718823586414\n",
      "Epoch: 62 | Loss: 0.41835702066087344\n",
      "Epoch: 63 | Loss: 0.41737572383719995\n",
      "Epoch: 64 | Loss: 0.4163847953729086\n",
      "Epoch: 65 | Loss: 0.4154337593964615\n",
      "Epoch: 66 | Loss: 0.41450008506334696\n",
      "Epoch: 67 | Loss: 0.4135664964891495\n",
      "Epoch: 68 | Loss: 0.41265950152269115\n",
      "Epoch: 69 | Loss: 0.4117883952164393\n",
      "Epoch: 70 | Loss: 0.4109130456309316\n",
      "Epoch: 71 | Loss: 0.4100636845699225\n",
      "Epoch: 72 | Loss: 0.4092116803865363\n",
      "Epoch: 73 | Loss: 0.40840348157447415\n",
      "Epoch: 74 | Loss: 0.4075754050387075\n",
      "Epoch: 75 | Loss: 0.40677787652542424\n",
      "Epoch: 76 | Loss: 0.4059838153868731\n",
      "Epoch: 77 | Loss: 0.40521665407273627\n",
      "Epoch: 78 | Loss: 0.4044711577106816\n",
      "Epoch: 79 | Loss: 0.403744178972813\n",
      "Epoch: 80 | Loss: 0.4031394286196708\n",
      "Epoch: 81 | Loss: 0.4024698065385452\n",
      "Epoch: 82 | Loss: 0.4017692953594681\n",
      "Epoch: 83 | Loss: 0.40108635177743795\n",
      "Epoch: 84 | Loss: 0.40044050360900885\n",
      "Epoch: 85 | Loss: 0.39977389362866184\n",
      "Epoch: 86 | Loss: 0.39913051795769816\n",
      "Epoch: 87 | Loss: 0.3985006850135472\n",
      "Epoch: 88 | Loss: 0.39788617527143866\n",
      "Epoch: 89 | Loss: 0.3973022135033491\n",
      "Epoch: 90 | Loss: 0.39668908064236785\n",
      "Epoch: 91 | Loss: 0.3960993803030959\n",
      "Epoch: 92 | Loss: 0.3955391884445868\n",
      "Epoch: 93 | Loss: 0.3949543217698082\n",
      "Epoch: 94 | Loss: 0.39437200508350617\n",
      "Epoch: 95 | Loss: 0.3938097856166727\n",
      "Epoch: 96 | Loss: 0.3932527093573543\n",
      "Epoch: 97 | Loss: 0.39269288944482833\n",
      "Epoch: 98 | Loss: 0.39216821476389263\n",
      "Epoch: 99 | Loss: 0.3916472716121482\n",
      "Epoch: 100 | Loss: 0.39113054743368725\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "from statistics import mean\n",
    "loss_values = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(-1))\n",
    "        loss_values.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1} | Loss: {mean(loss_values)}\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.34630037202284886\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for X, y in test_dataloader:\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y.unsqueeze(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss / len(test_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 4128 test instances: 0.2180232558139535%\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
