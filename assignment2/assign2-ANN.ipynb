{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]] [4.526 3.585 3.521 ... 0.923 0.847 0.894]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "print(X,y)\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HousingData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "# Instantiate training and test data\n",
    "train_data = HousingData(X_train, y_train)\n",
    "test_data = HousingData(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.layer_2 = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.1070971847042557\n",
      "Epoch: 2 | Loss: 0.8412891434029092\n",
      "Epoch: 3 | Loss: 0.7330059100337115\n",
      "Epoch: 4 | Loss: 0.6710677279173866\n",
      "Epoch: 5 | Loss: 0.6307103992663613\n",
      "Epoch: 6 | Loss: 0.6021839167046763\n",
      "Epoch: 7 | Loss: 0.5807244102506675\n",
      "Epoch: 8 | Loss: 0.5639104223052083\n",
      "Epoch: 9 | Loss: 0.5501812732394249\n",
      "Epoch: 10 | Loss: 0.5385994086720685\n",
      "Epoch: 11 | Loss: 0.5286641561382248\n",
      "Epoch: 12 | Loss: 0.519904711435354\n",
      "Epoch: 13 | Loss: 0.512121262876278\n",
      "Epoch: 14 | Loss: 0.5050634929697841\n",
      "Epoch: 15 | Loss: 0.4986296433310484\n",
      "Epoch: 16 | Loss: 0.49275906198087704\n",
      "Epoch: 17 | Loss: 0.4873521810714317\n",
      "Epoch: 18 | Loss: 0.48236125692224624\n",
      "Epoch: 19 | Loss: 0.47773468414164233\n",
      "Epoch: 20 | Loss: 0.47342046810848304\n",
      "Epoch: 21 | Loss: 0.46942366949523584\n",
      "Epoch: 22 | Loss: 0.4656625215155798\n",
      "Epoch: 23 | Loss: 0.46215189247570093\n",
      "Epoch: 24 | Loss: 0.45882694526438333\n",
      "Epoch: 25 | Loss: 0.45572315972211747\n",
      "Epoch: 26 | Loss: 0.4528102569779649\n",
      "Epoch: 27 | Loss: 0.45005438770503103\n",
      "Epoch: 28 | Loss: 0.4474401375297395\n",
      "Epoch: 29 | Loss: 0.4450117085936617\n",
      "Epoch: 30 | Loss: 0.44269474242123213\n",
      "Epoch: 31 | Loss: 0.44054052537569377\n",
      "Epoch: 32 | Loss: 0.4384374714225473\n",
      "Epoch: 33 | Loss: 0.4364472910611316\n",
      "Epoch: 34 | Loss: 0.43454139113147616\n",
      "Epoch: 35 | Loss: 0.43269763509861525\n",
      "Epoch: 36 | Loss: 0.43095749779784864\n",
      "Epoch: 37 | Loss: 0.42927466581889523\n",
      "Epoch: 38 | Loss: 0.42772150517227403\n",
      "Epoch: 39 | Loss: 0.42628670511224875\n",
      "Epoch: 40 | Loss: 0.42494893604239753\n",
      "Epoch: 41 | Loss: 0.42359716319974733\n",
      "Epoch: 42 | Loss: 0.4223401464532886\n",
      "Epoch: 43 | Loss: 0.421022958615642\n",
      "Epoch: 44 | Loss: 0.4197733967149547\n",
      "Epoch: 45 | Loss: 0.41854939158110654\n",
      "Epoch: 46 | Loss: 0.41737127401760865\n",
      "Epoch: 47 | Loss: 0.41623376142255114\n",
      "Epoch: 48 | Loss: 0.41540002541914967\n",
      "Epoch: 49 | Loss: 0.41433166394154874\n",
      "Epoch: 50 | Loss: 0.41330692439462785\n",
      "Epoch: 51 | Loss: 0.41233480056720334\n",
      "Epoch: 52 | Loss: 0.4114226501181802\n",
      "Epoch: 53 | Loss: 0.4104992897549847\n",
      "Epoch: 54 | Loss: 0.40959766931765523\n",
      "Epoch: 55 | Loss: 0.4091032380418008\n",
      "Epoch: 56 | Loss: 0.4083173156211592\n",
      "Epoch: 57 | Loss: 0.40750530177105954\n",
      "Epoch: 58 | Loss: 0.4067103191254229\n",
      "Epoch: 59 | Loss: 0.40594792994300416\n",
      "Epoch: 60 | Loss: 0.40519826210342175\n",
      "Epoch: 61 | Loss: 0.4045275723679288\n",
      "Epoch: 62 | Loss: 0.40382503203919123\n",
      "Epoch: 63 | Loss: 0.40312229310496644\n",
      "Epoch: 64 | Loss: 0.40243604046729387\n",
      "Epoch: 65 | Loss: 0.4017711594985153\n",
      "Epoch: 66 | Loss: 0.4011136206076519\n",
      "Epoch: 67 | Loss: 0.4004805132722559\n",
      "Epoch: 68 | Loss: 0.399891123957881\n",
      "Epoch: 69 | Loss: 0.3993203300811537\n",
      "Epoch: 70 | Loss: 0.39872101613568967\n",
      "Epoch: 71 | Loss: 0.39814284966184993\n",
      "Epoch: 72 | Loss: 0.3975864593019833\n",
      "Epoch: 73 | Loss: 0.3970364313448034\n",
      "Epoch: 74 | Loss: 0.396535943948527\n",
      "Epoch: 75 | Loss: 0.39603175768787546\n",
      "Epoch: 76 | Loss: 0.3955364036698674\n",
      "Epoch: 77 | Loss: 0.395067531546863\n",
      "Epoch: 78 | Loss: 0.39456719150676023\n",
      "Epoch: 79 | Loss: 0.39406685699583466\n",
      "Epoch: 80 | Loss: 0.3937006450265415\n",
      "Epoch: 81 | Loss: 0.39325184572560445\n",
      "Epoch: 82 | Loss: 0.3928403980948283\n",
      "Epoch: 83 | Loss: 0.39239282760620564\n",
      "Epoch: 84 | Loss: 0.39197041760839935\n",
      "Epoch: 85 | Loss: 0.39153399369350267\n",
      "Epoch: 86 | Loss: 0.39118408524231996\n",
      "Epoch: 87 | Loss: 0.39080165422258556\n",
      "Epoch: 88 | Loss: 0.39039768221433035\n",
      "Epoch: 89 | Loss: 0.39000118202476713\n",
      "Epoch: 90 | Loss: 0.3896158153427048\n",
      "Epoch: 91 | Loss: 0.389219886037111\n",
      "Epoch: 92 | Loss: 0.3888364552275692\n",
      "Epoch: 93 | Loss: 0.38845702709742386\n",
      "Epoch: 94 | Loss: 0.3882116467005179\n",
      "Epoch: 95 | Loss: 0.38786316986341274\n",
      "Epoch: 96 | Loss: 0.3875081101805453\n",
      "Epoch: 97 | Loss: 0.38715085423670065\n",
      "Epoch: 98 | Loss: 0.3868224898592201\n",
      "Epoch: 99 | Loss: 0.38667640552740296\n",
      "Epoch: 100 | Loss: 0.3863572847600593\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "from statistics import mean\n",
    "loss_values = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_dataloader:\n",
    "        optimizer.relu()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(-1))\n",
    "        loss_values.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1} | Loss: {mean(loss_values)}\")\n",
    "\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3644461122842935\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for X, y in test_dataloader:\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y.unsqueeze(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss / len(test_dataloader)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
